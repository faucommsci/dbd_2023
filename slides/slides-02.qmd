---
title: "Einf√ºhrung & √úberblick"
subtitle: "Session 02"
date: 08 11 2023
date-format: "DD.MM.YYYY"
bibliography: references.bib
---

# üöß Under construction {background-image="img/slide_bg-section.png"}

Die Folien werden aktuell √ºberarbeitet, sind aber sp√§testens zur 2.Sitzung (08.11) online.

```{r under-construction-stop-render}
#| echo: false


knitr::knit_exit()
```

# Agenda {background-image="img/slide_bg-agenda.png"}

1.  [Organisation & Koordination](#organisation-koordination)
2.  [(Re-)Introduction to DBD](#reintroduction-dbd)
3.  [Herausforderungen von DBD](#sec3)
4.  [Rahmenbedingungen von DBD](#sec4)

# Organisation & -koordination {#organisation-koordination background-image="img/slide_bg-orga.png"}

```{r setup-slide-session}
#| echo: false
# Load packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
    here, 
    tidyverse,
    gt
)

# Load schedule
source(here("slides/schedule.R"))
```

## Abstimmung des Semesterplans

#### Optionen zur Auswahl

::: columns
::: {.column width="50%"}
```{r table-schedule-a}
#| echo: false 
new_schedule_a %>% 
    gt::gt() %>% 
    gt::tab_header("Option A") %>% 
    gt::fmt_markdown() %>% 
    gt::tab_options(
        table.width = gt::pct(100), 
        table.font.size = "10px") %>% 
    gtExtras::gt_theme_nytimes() %>% 
    # mark session
    gtExtras::gt_highlight_rows(
        rows = 4,
        fill = "#C50F3C", alpha = 0.15,
        bold_target_only = TRUE,
        target_col = Topic
    ) %>%
    # mark past Session
    gt::tab_style(
        style = cell_text(
            style = "italic", 
            color = "grey"),
        location = cells_body(
            columns = everything(), 
            rows = 2:3)
    )
```
:::

::: {.column width="50%"}
```{r table-schedule-b}
#| echo: false 
new_schedule_b %>% 
    gt::gt() %>% 
    gt::tab_header("Option B") %>% 
    gt::fmt_markdown() %>% 
    gt::tab_options(
        table.width = gt::pct(100), 
        table.font.size = "10px") %>% 
    gtExtras::gt_theme_nytimes() %>% 
    # mark session
    gtExtras::gt_highlight_rows(
        rows = 4,
        fill = "#C50F3C", alpha = 0.15,
        bold_target_only = TRUE,
        target_col = Topic
    ) %>%
    # mark past Session
    gt::tab_style(
        style = cell_text(
            style = "italic", 
            color = "grey"),
        location = cells_body(
            columns = everything(), 
            rows = 2:3)
    )
```
:::
:::

## Please vote!

#### Bitte an Umfrage teilnehmen

::: columns
::: {.column width="50%"}
<br>

Bitte scannen Sie den **QR-Code** oder nutzen Sie folgenden **Link** f√ºr die Teilnahme an einer kurzen Umfrage:

-   <https://www.menti.com/al3qwznms52z>

-   Temporary Access Code: **5623 9279**
:::

::: {.column width="50%"}
<br>

![](img/session-02/mentimeter_qr_seminargestaltung.png){fig-align="center" width="400"}
:::
:::

## Ergebnis

::: {style="position: relative; padding-bottom: 56.25%; padding-top: 35px; height: 0; overflow: hidden;"}
<iframe sandbox="allow-scripts allow-same-origin allow-presentation" allowfullscreen="true" allowtransparency="true" frameborder="0" height="315" src="https://www.mentimeter.com/app/presentation/al3r163tjys1xur1v35e4vbf5a9sr5rt/embed" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" width="420">

</iframe>
:::



# (Re-)Introduction to DBD {#reintroduction-dbd background-image="img/slide_bg-section.png"}

Was sind *digital behavior data?*

Und *was* k√∂nnen wir mit Ihnen *untersuchen*?

## DBD - Was ist das eigentlich?

#### Definition [@weller2021] und Kernbereiche (nach [GESIS](https://www.gesis.org/institut/digitale-verhaltensdaten))

::: columns
::: {.column width="50%"}
-   ... fasst eine **Vielzahl von m√∂glichen Datenquellen** zusammen, die verschiedene Arten von **Aktivit√§ten aufzeichnen** (*h√§ufig sogar "nur" als Nebenprodukt*)

-   ... k√∂nnen dabei helfen, **Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien** zu erkennen
:::

::: {.column width="50%"}
![](img/session-02/dbd-pillars.png){fig-align="center"}
:::
:::

::: notes
-   Unterschiedliche Heraus- bzw. Anforderungen (je nach Bereich)
:::

## Und f√ºr uns?

#### DBD im Kontext des Seminars

::: columns
::: {.column width="50%"}
<br>

-   Schwerpunkt: **Nutzung und Inhalte** von **soziale Medien**
-   **Computational Social Science** \[CSS\] **Verfahren**, z.B. zur Erhebung, Verarbeitung, Auswertung und Pr√§sentation
:::

::: {.column width="50%"}
[![](https://i0.wp.com/ediscoverytoday.com/wp-content/uploads/2023/04/2023InternetMinuteSized.png?w=565&ssl=1){fig-align="center" width="370"}](https://ediscoverytoday.com/2023/04/20/2023-internet-minute-infographic-by-ediscovery-today-and-ltmg-ediscovery-trends/)
:::
:::

## Ohne CSS keine DBD

#### Kurzer Exkurs zur Bedeutung von Computational Social Science

::: {.callout-important appearance="minimal"}
**Definition (Computational Social Science).**

We define CSS as the development and application of computational methods to complex, typically large-scale, human (sometimes simulated) behavioral data." [@lazer2020]
:::

**hilft dabei ...**

-   genuine digitale Ph√§nomene zu untersuchen

-   digitale Verhaltensdaten zu sammeln und vorzuverarbeiten

-   neue Methoden zur Analyse von gro√üen Datens√§tzen anzuwenden

::: notes
CSS = neues Teilgebiet der Sozialwissenschaften oder neuer "Werkzeugkasten" zur Erg√§nzung der traditionellen sozialwissenschaftlichen Ans√§tze
:::

## Und was k√∂nnen wir damit untersuchen?

#### Beispiele f√ºr & Kategorisierung von untersuchbaren Verhalten & Interaktionen

::: columns
::: {.column width="65%"}
![Quelle: [@keusch2021]](img/session-02/dbd_matrix.png){fig-align="center" width="1024"}
:::

::: {.column width="35%"}
<br>

##### **Einschr√§nkungen**

-   Kategorisierung ist **Momentaufnahme** und nicht √ºberschneidungsfrei

-   **Selektive Nutzung** von bestimmten digitalen Ger√§ten bzw. Funktionen
:::
:::

::: notes
-   Kategorien: Digital/Analog individual/social behavior

-   Einige inh√§rent digitale Verhalten (z.B. Web Searches) bei zunehmender Digitalisierung von analogen Verhalten (z.B. Collaborative Work)

-   Fehlen digitaler Spurendaten in all diesen Quadranten f√ºr bestimmte Personen und bestimmte Verhaltensweisen durch selektive Nutzung digitaler Ger√§te.
:::

## Verf√ºgbarkeit als Pluspunkt

#### DBD als wertvolle Quelle bei aktuellen, sensiblen & unvorhersehbaren Themen

<br>

**Einsatz besonders Vorteilhaft bei Themen bzw. Untersuchungen ...**

-   ... f√ºr die es **schwierig** ist, Studienteilnehmer\*innen zu **rekrutieren**
-   ... bei denen **Beobachtungen** **vorteilhafter** sind als Befragungen

***Beispiel: Streaming und/oder Mining von Inhalten aus bestehenden digitalen Kommunikationsstr√∂men***

-   **Zeitnaher** als die Erstellung einer Umfrage
-   Zus√§tzlicher Nutzen als **Archiv** bei **unvorhersehbaren** **Ereignissen**

::: notes
üîî --\> Beispiele?

-   Meinung zu Corona auf Basis von Tweets

-   Well-being auf Basis von Instagram-Bildern & Texten
:::

## Mehr Daten durch technologischen Fortschritt

#### Beispiel: Wachsenden Anzahl eingebauter Smartphone-Sensoren

![Graphik aus @struminskaya2020](img/session-02/dbd_smartphone_development.jpeg){fig-align="center"}

<!--# TODO: Bedeutung/Funktion der einzelnen Sensoren -->

## Eine kleine Lobeshymne auf DBD

#### Zwischenfazit

-   Digitale Ger√§te oder **Sensoren** k√∂nnen sich besser an bestimmte Fakten **besser "erinnern"** als das menschliche Ged√§chtnis.

-   Sensoren sind oft bereits **in allt√§gliche Technologie eingebaut** und produzieren digitale Verhaltensdaten als ein "Nebenprodukt".

-   Unaufdringliche Erfassung als potentieller Vorteil bzw. **Entlastung f√ºr Teilnehmer\*Innen**

-   **Kombination mit Umfragedaten** m√∂glich (und [bereichernd]{.rn rn-type="underline" rn-color="#E6002E"}!)

::: fragment
::: {.rn rn-type="box" rn-color="#E6002E"}
**Aber:**

Zur erfolgreichen Nutzung m√ºssen [Forschungsziele & verf√ºgbare Daten in Einklang]{.rn rn-type="highlight"} gebracht, m√∂gliche [Biases und methodische Probleme]{.rn rn-type="highlight"} ber√ºcksichttigt sowie die [Datenqualit√§t]{.rn rn-type="highlight"} evaluiert werden.
:::
:::

::: notes
‚ñ∂Ô∏è
:::

# Herausforderungen von DBD {#sec3 background-image="img/slide_bg-section.png"}

Der Umgang mit Biases, methodischen T√ºcken und ethischen Einschr√§nkungen

## Wenn der Vorteil zum Nachteil wird

#### Ambivalenz der Unaufdringlichkeit [@keusch2021]

-   Unterscheidung zwischen **aufdringlichen** *(z.B. spezielle Research-App & Befragungen)* **& unaufdringlichen** *(z.B. Cookies, Browserplugins & APIs)* **erhobenen Daten**

-   **Bewertung** und Erwartung an Datensammlung ist **abh√§ngig vom Kontex**t (*z.B. Amazon vs. Researchgate*)

::: fragment
::: {.rn rn-type="box" rn-color="#E6002E"}
[**Dilema:**]{.rn rn-type="circle" rn-color="#E6002E"}

Einerseits bereitwillige (oft unwissende) [Abgabe]{.rn rn-type="highlight"} der Daten [an Konzerne]{.rn rn-type="highlight"}, andererseits h√§ufig [Bedenken]{.rn rn-type="highlight"} bez√ºglich Datenschutz & Privatsph√§re bei [wissenschaftlichen Studien]{.rn rn-type="highlight"}
:::
:::

::: notes
‚ñ∂Ô∏è \| üîî --\> Gr√ºnde f√ºr Ablehnung: Nutzenorientierung?
:::

## The End of Theory

::: {.fragment fragment-index="1"}
#### Zur Wichtigkeit von konzipierte Messungen & Designs
:::

> ["Who knows why people do what they do? The point is they do it, and we can track and measure it with unprecedented fidelity. With enough data, the numbers speak for themselves."]{.rn rn-type="strike-through" rn-color="#E6002E" rn-multiline="true"}[@anderson2008]

::: {.fragment .semi-fade-out fragment-index="1"}
### Was denken Sie?
:::

::: {.fragment fragment-index="1"}
> "Size alone does [not]{.rn rn-type="underline" rn-color="#E6002E"} necessarily make the data better" [@boyd2007]

> "There are a lot of small data problems that occur in big data \[which\] don't disappear because you've got lots of the stuff. [They get worse.]{.rn rn-type="underline" rn-color="#E6002E"}" [@harford2014]
:::

::: notes
‚ñ∂Ô∏è \| üîî
:::

## We need to talk about [biases]{.smallcaps}

#### Spezifische und allgemeine Herausforderungen f√ºr die Forschung mit DBD

**Hintergrund**: (*Big) Data ist zunehmend Grundlage f√ºr politische Ma√ünahmen, die Gestaltung von Produkten und Dienstleistungen und f√ºr die automatisierte Entscheidungsfindung*

-   **Herausforderungen in Bezug auf DBD-Forschung:** fehlender Konsens √ºber ein Vokabular oder eine Taxonomie, h√§ufig nur impliziter Bezug in der Forschung

-   **Generelle Herausforderung:** [bias]{.rn rn-type="box" rn-color="#e6002e"} ist ein weit gefasster & in unterschiedlichen Disziplinen genutzter Begriff\

::: notes
‚ñ∂Ô∏è

"bias" hier im statistischen Sinne

Punkt2:

-   *conformation bias* und andere kognitive Voreingenommenheiten (Croskerry, 2002)

-   systemische, diskriminierende Ergebnisse (Friedman und Nissenbaum, 1996)

-   systemische Sch√§den (Barocas et al., 2017)
:::

<!--# Was bedeuten hier "systematische Sch√§de"-->

## Know your bias!

#### Framework zur Minimierung von Fehlern und Problemen [@olteanu2019]

![](img/session-02/bias_framework_without_legend.png){fig-align="center"}

::: notes
Beschreibung:

-   Die Analyse sozialer Daten beginnt mit bestimmten Zielen (Abschnitt 2.1), wie dem Verst√§ndnis oder der Beeinflussung von Ph√§nomenen, die f√ºr soziale Plattformen spezifisch sind (Typ I) und/oder von Ph√§nomenen, die √ºber soziale Plattformen hinausgehen (Typ II).

-   Diese Ziele erfordern, dass die Forschung bestimmte Validit√§tskriterien erf√ºllt, die weiter oben beschrieben wurden (Abschnitt 2.2).

-   Diese Kriterien k√∂nnen ihrerseits durch eine Reihe von allgemeinen Verzerrungen und Problemen beeintr√§chtigt werden (Abschnitt 3).

-   Diese Herausforderungen k√∂nnen von den Merkmalen der einzelnen Datenplattformen (Abschnitt 4) abh√§ngen - die oft nicht unter der Kontrolle des Forschers stehen - und von den Entscheidungen des Forschungsdesigns entlang einer Datenverarbeitungspipeline (Abschnitte 5 bis 8) - die oft unter der Kontrolle des Forschers stehen.

-   Pfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken
:::

# Wichtige Rahmenbedingungen {#sec4 background-image="img/slide_bg-section.png"}

Ethik & Recht im Fokus

## Erweiterung des Blickwinkels

#### Ethische Erw√§gungen bei DBD-Forschung

::: {style="font-size: smaller;"}
**Aus √∂ffentlicher Zug√§nglich- bzw. Verf√ºgbarkeit von Daten leitet sich nicht automatisch ethische Verwertbarkeit ab** [@zimmer2010; @boyd2012]

-   Verletzung der Privatsph√§re der Nutzer [@goroff2015]

-   Erm√∂glichung von rassischem, sozio√∂konomischem oder geschlechtsspezifischem Profiling [@barocas2016]

##### **Negative Beispiele**

-   **Facebook contagion experiment (**2012-2014): Feeds von Nutzer\*Innen so manipulierten, dass sie je nach den ge√§u√üerten Emotionen mehr oder weniger von bestimmten Inhalten enthielten [@kramer2014]

-   **Encore-Forschungsprojekt**: Messung der Internetzensur auf der ganzen Welt, bei der Webbrowser angewiesen wurden, zu versuchen, sensible Webinhalte ohne das Wissen oder die Zustimmung der Nutzer herunterzuladen [@burnett2014]
:::

::: notes
Hintergrund:

-   Ethische Fragen bisher epistemische Bedenken (Verwendung von nicht schl√ºssigen oder fehlgeleiteten Beweisen), jetzt normativ Bedenken (Folgen der Forschung)
-   Forschung grunds√§tzlich in vielen L√§ndern gesetztlich geregelt

Negativbeispiele:

-   Facebook contagion experiment: Das Experiment wurde als ein Eingriff kritisiert, der den emotionalen Zustand von ahnungslosen Nutzern beeinflusste, die keine Zustimmung zur Teilnahme an der Studie gegeben hatten (Hutton und Henderson, 2015a).

-   Encore-Forschngsprojekt: Menschen in einigen L√§ndern durch diese Zugriffsversuche m√∂glicherweise gef√§hrdet wurden

Folgende Abschnitte:

-   zentrales Spannungsverh√§ltnis in der Forschungsethik digitaler Daten dargestellt.

-   Anschlie√üend wird die Diskussion spezifischer ethischer Probleme in der Sozialdatenforschung im Hinblick auf drei grundlegende Kriterien gegliedert, die im Belmont-Bericht (Ryan et al., 1978), einem grundlegenden Werk zur Forschungsethik, vorgebracht wurden: Autonomie (Abschnitt 9.2), Wohlt√§tigkeit (Abschnitt 9.3) und Gerechtigkeit (Abschnitt 9.4).
:::

## Ein schmaler Grat

#### Forschungethik bei digitalen Daten

**Hintergrund**: *Die Herausforderung besteht in der Kombination von zwei extremen Sichtweisen, der Betrachtung der Forschung mit sozialen Daten als "klinische" Forschung oder als Computerforschung*

-   Die Sozialdatenforschung **unterscheidet sich von klinischen Versuchen**.

-   **Ethische Entscheidungen** in der Sozialdatenforschung m√ºssen **gut √ºberlegt sein**, da oft sind mehrere Werte betroffen, die miteinander in Konflikt stehen k√∂nnen

::: notes
Hintergrund:

1.  Die Sozialdatenforschung √§hnelt klinischen Versuchen und anderen Experimenten am Menschen in ihrer F√§higkeit, Menschen zu schaden, und sollte daher auch als solche reguliert werden

2.  die Sozialdatenforschung √§hnelt der sonstigen Computerforschung, die sich traditionell auf Methoden, Algorithmen und den Aufbau von Systemen konzentriert, mit minimalen direkten Auswirkungen auf Menschen.

Punkt 2: Sch√§den, die die √ºblichen Arten der Sozialdatenforschung ( z. B. die Verletzung der Privatsph√§re oder der Anblick verst√∂render Bilder)verursachen k√∂nnen, oft nicht mit Sch√§den von klinischen Versuchen gleichzusetzen

Punkt 3: Datenanalyse beispielsweise erforderlich sein, um wichtige Dienste bereitzustellen, und es sollten L√∂sungen erwogen werden, die ein Gleichgewicht zwischen Datenschutz und Genauigkeit herstellen (Goroff, 2015).
:::

## Achtung der individuellen Autonomie

#### Diskussion der Informierte Zustimmung als Indikator autonomer Entscheidung

<br>

::: {style="font-size: smaller"}
**Die Einwilligung nach Aufkl√§rung setzt voraus, dass**

1.  die Forscher\*Innen den potenziellen Teilnehmenden alle **relevanten Informationen offenlegen**;
2.  die potenziellen Teilnehmenden **in der Lage** sind, diese **Informationen zu bewerten;**
3.  die potenziellen Teilnehmenden **freiwillig entscheiden** k√∂nnen, ob sie **teilnehmen** wollen oder nicht;
4.  die Teilnehmenden den Forschernden ihre **ausdr√ºckliche Erlaubnis erteilen**, h√§ufig in schriftlicher Form; und
5.  die Teilnehmende die M√∂glichkeit haben, ihre **Einwilligung jederzeit zur√ºckzuziehen**.
:::

## Achtung der individuellen Autonomie

#### Diskussion der Informierte Zustimmung als Indikator autonomer Entscheidung

::: {style="font-size: smaller; color: #04316A40;"}
**Die Einwilligung nach Aufkl√§rung setzt voraus, dass**

1.  die Forscher\*Innen den potenziellen Teilnehmenden alle **relevanten Informationen offenlegen**;
2.  die potenziellen Teilnehmenden **in der Lage** sind, diese **Informationen zu bewerten;**
3.  die potenziellen Teilnehmenden **freiwillig entscheiden** k√∂nnen, ob sie **teilnehmen** wollen oder nicht;
4.  die Teilnehmenden den Forschernden ihre **ausdr√ºckliche Erlaubnis erteilen**, h√§ufig in schriftlicher Form; und
5.  die Teilnehmende die M√∂glichkeit haben, ihre **Einwilligung jederzeit zur√ºckzuziehen**.
:::

##### **Potentielle Probleme**

-   Die **Zustimmung** von **Millionen** von Nutzern einzuholen ist **unpraktisch**.

-   Das **√∂ffentliche Teilen** von Inhalten im Internet **bedeutet nicht** unbedingt eine **Zustimmung** zur Forschung\[\^1\].

-   Die **Nutzungsbedingungen** sozialer Plattformen stellen m√∂glicherweise **keine informierte Zustimmung** zur Forschung dar.

::: {style="font-size: x-small;"}
:::

::: notes
Beispiel 1:

-   H√§ufig keine Zustimmung bei Studien mit Daten von Millionen von Social-Media-Nutzern (Zimmer, 2010; Hutton und Henderson, 2015a)

-   Obwohl die Einholung der Zustimmung oft als unpraktisch angesehen wird (Boyd und Crawford, 2012), gibt es Bem√ºhungen, Methoden zur Einholung der Zustimmung zu entwickeln, die den Aufwand f√ºr die Teilnehmer m√∂glichst gering halten (Hutton und Henderson, 2015a).
:::

## Wohlt√§tigkeit und Unsch√§dlichkeit als Ziel

#### Bewertung von Risken & Nutzen

::: {style="font-size: smaller;"}
**Hintergrund**: *Nicht nur Fokus auf den Nutzen der Forschung, sondern auch auf die m√∂glichen Arten von Sch√§den, die betroffenen Gruppen und die Art und Weise, wie nachteilige Auswirkungen getestet werden k√∂nnen .* [@sweeney2013][@sweeney2013]

###### Potentielle Probleme

-   **Daten** √ºber **Einzelpersonen** k√∂nnen ihnen **schaden, wenn** sie **offengelegt** werden[^1][^2].

-   **Forschungsergebnisse** **k√∂nnen** verwendet werden, um **Schaden** anzurichten[^3].

-   **"Dual-Use"- und Sekund√§ranalysen** sind in der Sozialdatenforschung **immer** **h√§ufiger** anzutreffen[^4].
:::

[^1]: Stalking, Diskriminierung, Erpressung oder Identit√§tsdiebstahl (Gross und Acquisti, 2005).

[^2]: Zu lange Archivierung personenbezogener Daten oder die √∂ffentliche Freigabe schlecht anonymisierter Datens√§tze kann zu Verletzungen der Privatsph√§re f√ºhren, da diese Daten mit anderen Quellen kombiniert werden k√∂nnen, um Erkenntnisse √ºber Personen ohne deren Wissen zu gewinnen (Crawford und Finn, 2014; Goroff, 2015; Horvitz und Mulligan, 2015)

[^3]: Abgesehen von der Tatsache, dass aus sozialen Daten gezogene R√ºckschl√ºsse in vielerlei Hinsicht falsch sein k√∂nnen, wie in dieser Studie hervorgehoben wird, k√∂nnen zu pr√§zise R√ºckschl√ºsse dazu f√ºhren, dass Menschen in immer kleinere Gruppen eingeteilt werden k√∂nnen (Barocas, 2014).

[^4]: Daten, Instrumente und Schlussfolgerungen, die f√ºr einen bestimmten Zweck gewonnen wurden, f√ºr einen anderen Zweck verwendet werden (Hovy und Spruit, 2016; Benton et al., 2017)

::: notes
Die Forschung zu sozialen Daten wird mit bestimmten Arten von Sch√§den in Verbindung gebracht, von denen die Verletzung der Privatsph√§re vielleicht die offensichtlichste ist (Zimmer, 2010; Crawford und Finn, 2014).

Beispiel 1: Einige prominente Beispiele sind die Datenpanne bei Ashley Madison im Jahr 2015, bei der einer Website, die sich als Dating-Netzwerk f√ºr betr√ºgerische Ehepartner anpreist, Kontoinformationen (einschlie√ülich der vollst√§ndigen Namen der Nutzer) gestohlen und online gestellt wurden (Thomsen, 2015), sowie die j√ºngsten Datenpannen bei Facebook, bei denen Hunderte Millionen von Datens√§tzen mit Kommentaren, Likes, Reaktionen, Kontonamen, App-Passw√∂rtern und mehr √∂ffentlich gemacht wurden.
:::

## Faire Verteilung von Risiken & Nutzen {.smaller}

#### Recht & Gerechtigkeit

**Annahme**: *Es ist von Anfang an bekannt, wer durch die Forschung belastet wird und wer von den Ergebnissen profitieren wird.*

<br>

###### Potentielle Probleme

-   Die **digitale Kluft** kann das Forschungsdesign beeinflussen[^5] (Stichwort: WEIRD Samples)

-   **Algorithmen** und Forschungsergebnisse k√∂nnen zu **Diskriminierung** f√ºhren.

-   **Forschungsergebnisse** sind m√∂glicherweise **nicht** allgemein **zug√§nglich**[^6].

-   Nicht alle **Interessengruppen** werden √ºber die Verwendung von Forschungsergebnissen konsultiert[^7].

[^5]: Data divide: mangelnde Verf√ºgbarkeit von hochwertigen Daten √ºber Entwicklungsl√§nder und unterprivilegierte Gemeinschaften (Cinnamon und Schuurman, 2013).

[^6]: **Idealerweise sollten die Menschen Zugang zu den Forschungsergebnissen und Artefakten haben, die aus der Untersuchung ihrer pers√∂nlichen Daten entstanden sind (Gross und Acquisti, 2005; Crawford und Finn, 2014).**

[^7]: In die √úberlegungen dar√ºber, wie, f√ºr wen und wann Forschungsergebnisse umgesetzt werden, sollten diejenigen einbezogen werden, die m√∂glicherweise betroffen sind oder deren Daten verwendet werden (Costanza-Chock, 2018; Design Justice, 2018; Green, 2018)

::: notes
üîî-\> Plausibilit√§t der Annahme?
:::

## Zwei Trends, Drei Fragen, Vier Empfehlungen {.smaller}

#### Zusammenfassung und Ausblick

**Trend 1: Eine zunehmende Skepsis gegen√ºber einfachen Antworten**

1.  Wie einstehen die Daten, was enthalten sie tats√§chlich und wie die Arbeitsdatens√§tze zusammengestellt?

2.  Wird deutlich, was was ausgewertet wird?

3.  Wird die Verwendung von vorgefertigten Datens√§tzen und Modellen des maschinellen Lernens hinterfragt?

<br>

**Trend 2: Vom Aufwerfen von Bedenken √ºber soziale Daten zum Umgang mit ihnen. 4 Empfehlungen:**

1.  **Detaillierte Dokumentation** und kritische **Pr√ºfung** der Datensatz- und Modellerstellung

2.  DBD-Studien auf v**erschiedene Plattformen, Themen, Zeitpunkte und Teilpopulationen auszuweiten**, um festzustellen, wie sich die Ergebnisse beispielsweise in verschiedenen kulturellen, demografischen und verhaltensbezogenen Kontexten unterscheiden

3.  **Transparenzmechanismen** zu schaffen, die es erm√∂glichen, soziale Software zu √ºberpr√ºfen und Verzerrungen in sozialen Daten an der Quelle zu evaluieren

4.  **Forschung** zu diesen Leitlinien, Standards, Methoden und Protokollen **auszuweiten** und ihre √úbernahme zu f√∂rdern.

    ::: notes
    Schlie√ülich gibt es angesichts der Komplexit√§t der inh√§rent kontextabh√§ngigen, anwendungs- und bereichsabh√§ngigen Verzerrungen und Probleme in sozialen Daten und Analysepipelines, die in diesem Papier behandelt werden, keine Einheitsl√∂sungen - bei der Bewertung und Bek√§mpfung von Verzerrungen ist Nuancierung entscheidend.
    :::

# Bis zur n√§chsten Sitzung! {background-image="img/slide_bg-end_session.png"}

## Literatur

::: {#refs}
:::